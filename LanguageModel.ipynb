{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"LanguageModel.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d722d511a966469c8ed41de8dd502880":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2fcfecfdb35a4b5db1c251b4d485330b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9db65a244f8442b99019c913e88b2f49","IPY_MODEL_43d7dc52abf0409e880abbed3c185a5a"]}},"2fcfecfdb35a4b5db1c251b4d485330b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9db65a244f8442b99019c913e88b2f49":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bb1d3f1538f94a7a88263b32f52a411b","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":31254,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":31254,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_23df277dcbed4791b823b5cc909e4209"}},"43d7dc52abf0409e880abbed3c185a5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_986c599f712e461ba4ad5ab69ab499b3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 31254/31254 [21:09&lt;00:00, 24.63it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e78429c3ea7945ffb400f830b9b6aad3"}},"bb1d3f1538f94a7a88263b32f52a411b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"23df277dcbed4791b823b5cc909e4209":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"986c599f712e461ba4ad5ab69ab499b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e78429c3ea7945ffb400f830b9b6aad3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fe4a92a520d24cda9b8fe62676e02bba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_98584143c43f4076a3e8d2e07615d6ec","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d8af1a07b32c459e97e5f583bb53896a","IPY_MODEL_d0e75d96b8574de88acd1dee13f9e276"]}},"98584143c43f4076a3e8d2e07615d6ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d8af1a07b32c459e97e5f583bb53896a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bbc91f3fc74241588efee4d06cd71c4a","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":7814,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7814,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d1b0c93ff0f3412095a52a5e1a1e6bba"}},"d0e75d96b8574de88acd1dee13f9e276":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_40a24b5413234b5194dcc277a80cb886","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7814/7814 [37:02&lt;00:00,  3.52it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bd09d0f05de24db7bbdf1b18b08dcba5"}},"bbc91f3fc74241588efee4d06cd71c4a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d1b0c93ff0f3412095a52a5e1a1e6bba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"40a24b5413234b5194dcc277a80cb886":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bd09d0f05de24db7bbdf1b18b08dcba5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"24a6e47e5ea4495f99fc403562e18eff":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4b8bd8ec1dd24a5aa99652b19b1871ad","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f97f099027004a39aeb5ae41c41ea1a8","IPY_MODEL_67852cc093b74531a29603b009dfe687"]}},"4b8bd8ec1dd24a5aa99652b19b1871ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f97f099027004a39aeb5ae41c41ea1a8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ac7356e9363647d79856be1f7e416f1f","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":9767,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9767,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_10c19c29c472420698c5f9fd2d103467"}},"67852cc093b74531a29603b009dfe687":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cd464464946c4e2e9e7768bd074821ef","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9767/9767 [37:28&lt;00:00,  4.34it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_95936afe63044fd19c9f391176b808f5"}},"ac7356e9363647d79856be1f7e416f1f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"10c19c29c472420698c5f9fd2d103467":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cd464464946c4e2e9e7768bd074821ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"95936afe63044fd19c9f391176b808f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d51c9e0f78854cfeb5bb855fbe422ab3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d46d82a12a6447d088a9bfe6d8f4a8cf","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_91dba16960644e11a837b4afb44dfdcb","IPY_MODEL_83647abfc49546ecbea86af79b43a695"]}},"d46d82a12a6447d088a9bfe6d8f4a8cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"91dba16960644e11a837b4afb44dfdcb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_51acc15257b44283bca6041076714cb4","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":31254,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":31254,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_70594bdab64e4dd78218ed5bc4ef558b"}},"83647abfc49546ecbea86af79b43a695":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_709c5a63f994401ebf4f721a1658d7b9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 31254/31254 [16:11&lt;00:00, 32.16it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_02bd4bebdca64735942a4ae8deb70b62"}},"51acc15257b44283bca6041076714cb4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"70594bdab64e4dd78218ed5bc4ef558b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"709c5a63f994401ebf4f721a1658d7b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"02bd4bebdca64735942a4ae8deb70b62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"05b3d57f4cda4a29a090c60d7f589a05":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4c77618388484a1ab737ace3cbd27413","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_30d77050be274a65ae8b961715cf1907","IPY_MODEL_b3c5c26d026a49c2b20daaeb961ec9cb"]}},"4c77618388484a1ab737ace3cbd27413":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"30d77050be274a65ae8b961715cf1907":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_77735c881b08402aa3b307c42d3a6b09","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":7814,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7814,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bf5c3dd4e7564507bb65408f9309b43e"}},"b3c5c26d026a49c2b20daaeb961ec9cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8bc06ac14e444963a063dd604a56b3da","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7814/7814 [16:08&lt;00:00,  8.07it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_264e3bc21f354046a6c072dfdb10f9b5"}},"77735c881b08402aa3b307c42d3a6b09":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bf5c3dd4e7564507bb65408f9309b43e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8bc06ac14e444963a063dd604a56b3da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"264e3bc21f354046a6c072dfdb10f9b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4146195ebaa4417bb4fd7f3057aa1fb6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_20fe57d23a2c4b99a40f4ec57fc5a552","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5339db67b25e4be5ba82615109f794b8","IPY_MODEL_0cfddcc98eff47f9be514586fa1e1cab"]}},"20fe57d23a2c4b99a40f4ec57fc5a552":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5339db67b25e4be5ba82615109f794b8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bd3dec50e01c4082ae3bb2a136066577","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":9767,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9767,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c211c28f87564969819b274cb93a7a7f"}},"0cfddcc98eff47f9be514586fa1e1cab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9113199af6b741dfbcd2a6dfdc88e42b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9767/9767 [19:12&lt;00:00,  8.47it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f41176fe41f24e8399bb04574002a902"}},"bd3dec50e01c4082ae3bb2a136066577":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c211c28f87564969819b274cb93a7a7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9113199af6b741dfbcd2a6dfdc88e42b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f41176fe41f24e8399bb04574002a902":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"hjs4Ds40J_Ad"},"source":["import random\r\n","import numpy as np\r\n","import torch\r\n","import pandas as pd\r\n","from tqdm.notebook import tqdm\r\n","import nltk\r\n","from torch.utils.data import Dataset, random_split\r\n","import re\r\n","# from spellchecker import SpellChecker\r\n","from nltk import word_tokenize, sent_tokenize\r\n","import string\r\n","from tqdm.notebook import tqdm\r\n","from sklearn.model_selection import train_test_split, TimeSeriesSplit\r\n","from collections import Counter, defaultdict\r\n","import torch.nn as nn\r\n","import copy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aHK_mbdzMZwm"},"source":["random.seed(42)\r\n","np.random.seed(42)\r\n","torch.manual_seed(42)\r\n","if torch.cuda.is_available():\r\n","    torch.cuda.manual_seed_all(42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NJxOCM0Fa2ii"},"source":["def decontracted(phrase):\r\n","    # specific\r\n","    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\r\n","    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\r\n","\r\n","    # general\r\n","    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\r\n","    phrase = re.sub(r\"\\'re\", \" are\", phrase)\r\n","    phrase = re.sub(r\"\\'s\", \" is\", phrase)\r\n","    phrase = re.sub(r\"\\'d\", \" would\", phrase)\r\n","    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\r\n","    phrase = re.sub(r\"\\'t\", \" not\", phrase)\r\n","    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\r\n","    phrase = re.sub(r\"\\'m\", \" am\", phrase)\r\n","    return phrase"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6MFhbJQuk2jO"},"source":["def correct_spellings(text):\r\n","    spell = SpellChecker()\r\n","    corrected_text = []\r\n","    misspelled_words = spell.unknown(text.split())\r\n","    for word in text.split():\r\n","        if word in misspelled_words:\r\n","            corrected_text.append(spell.correction(word))\r\n","        else:\r\n","            corrected_text.append(word)\r\n","    return \" \".join(corrected_text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lam56XqwyW54","executionInfo":{"status":"ok","timestamp":1612866133178,"user_tz":-180,"elapsed":5560,"user":{"displayName":"Айдар Валиев","photoUrl":"","userId":"09476818626072365934"}},"outputId":"b985c9e1-89e2-4966-e3e5-aeefc09f1081"},"source":["PAD = \"<PAD>\"\r\n","EOS = \"<EOS>\"\r\n","UNK = \"<UNK>\"\r\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"83wNieSBN5vq"},"source":["def tokenize_adv(sent):\r\n","  text = decontracted(sent.lower())\r\n","  text = re.sub(r'[^\\w\\s]', '', text)\r\n","  table = text.maketrans('', '', string.punctuation)\r\n","  text = text.translate(table)\r\n","  # sent = correct_spellings(sent)\r\n","  words = word_tokenize(text)\r\n","  return words "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i8uUWmnDz9px","executionInfo":{"status":"ok","timestamp":1612866134085,"user_tz":-180,"elapsed":6053,"user":{"displayName":"Айдар Валиев","photoUrl":"","userId":"09476818626072365934"}},"outputId":"355076eb-e223-4285-e412-2199e8ded7c3"},"source":["!wget https://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-02-09 10:22:12--  https://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt\n","Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n","Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4573338 (4.4M) [text/plain]\n","Saving to: ‘shakespeare_input.txt’\n","\n","shakespeare_input.t 100%[===================>]   4.36M  11.3MB/s    in 0.4s    \n","\n","2021-02-09 10:22:12 (11.3 MB/s) - ‘shakespeare_input.txt’ saved [4573338/4573338]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fqEJFD9I1Kkp"},"source":["with open('shakespeare_input.txt', 'r') as f:\r\n","    data = f.read().lower()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IGTvcpGv1y6n"},"source":["sonnets = data.split('\\n\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wgr9rcSb8aoF"},"source":["sonnets = []\r\n","for son in data.split('\\n\\n'):\r\n","  son = re.sub(r'[\\s\\w]*:\\n','',son.lower())\r\n","  son = re.sub(r'\\n',' ',son)\r\n","  sonnets.append(son)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N_fuZUpMVuJr"},"source":["sentences = []\r\n","for son in sonnets:\r\n","  sent = sent_tokenize(son)\r\n","  sentences = sentences + sent"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H5AaREDyiyLW"},"source":["tokens=[]\r\n","for sent in sentences:\r\n","  words = tokenize_adv(sent) + [EOS]\r\n","  # if len(words)>3:\r\n","  tokens.append(words)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vgB7kFKaS0PR"},"source":["# train,test = tokens[:np.ceil(len(tokens) * 0.8).astype(int)],tokens[np.ceil(len(tokens) * 0.8).astype(int):]\r\n","trainval, test = train_test_split(tokens, test_size=0.2, random_state=42, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BTSqgYYVwzhj"},"source":["train, val = train_test_split(trainval, test_size=0.2, random_state=42, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HI6TxsSo3VTc"},"source":["len_tokens = {'train':len(train), 'val':len(val), 'test':len(test)}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nhj48gEt18SH","executionInfo":{"status":"ok","timestamp":1612866147630,"user_tz":-180,"elapsed":14937,"user":{"displayName":"Айдар Валиев","photoUrl":"","userId":"09476818626072365934"}},"outputId":"1fb8fbb8-c5d0-4323-dd2c-151c354b746c"},"source":["print('Lenght of train with 1/2-words sentences {0} \\nLenght of val  with 1/2-words sentences {1} \\nLenght of test  with 1/2-words sentences {2} \\n'.format(len(train), len(val), len(test)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Lenght of train with 1/2-words sentences 34038 \n","Lenght of val  with 1/2-words sentences 8510 \n","Lenght of test  with 1/2-words sentences 10638 \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tHx_i41T2rKx","executionInfo":{"status":"ok","timestamp":1612866153620,"user_tz":-180,"elapsed":12441,"user":{"displayName":"Айдар Валиев","photoUrl":"","userId":"09476818626072365934"}},"outputId":"da830f6a-ee45-4d40-f88c-ac25fa66cfea"},"source":["tokens=[]\r\n","for sent in sentences:\r\n","  words = tokenize_adv(sent) + [EOS]\r\n","  if len(words)>3:\r\n","    tokens.append(words)\r\n","trainval, test = train_test_split(tokens, test_size=0.2, random_state=42, shuffle=False)\r\n","train, val = train_test_split(trainval, test_size=0.2, random_state=42, shuffle=False)\r\n","print('Lenght of train with 1/2-words sentences {0} \\nLenght of val  with 1/2-words sentences {1} \\nLenght of test  with 1/2-words sentences {2} \\n'.format(len(train), len(val), len(test)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Lenght of train with 1/2-words sentences 31254 \n","Lenght of val  with 1/2-words sentences 7814 \n","Lenght of test  with 1/2-words sentences 9767 \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PTwXCLOY3ptk"},"source":["len_tokens_wo_1_2 = {'train':len(train), 'val':len(val), 'test':len(test)}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s7mcy4613ye8"},"source":["diff = len_tokens['train'] - len_tokens_wo_1_2['train'] + len_tokens['val'] - len_tokens_wo_1_2['val'] + len_tokens['test'] - len_tokens_wo_1_2['test']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rIFKllm64S-O","executionInfo":{"status":"ok","timestamp":1612866153623,"user_tz":-180,"elapsed":10210,"user":{"displayName":"Айдар Валиев","photoUrl":"","userId":"09476818626072365934"}},"outputId":"57f63f15-7c10-4806-ae08-06f919298db8"},"source":["diff/(sum(len_tokens.values()))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.08180724250742677"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"0nZk1W7K27rF"},"source":["Таким образом потери данных при отбрассывании 1/2 словных предложений составляют примерно 4351 предложение или 8%."]},{"cell_type":"markdown","metadata":{"id":"fW5kwqC0xCpy"},"source":["В принципе в обоих случаях можно обойтисть только тестом и трейном. Но для обеспечения более непредвзятой оценки выделим еще и валидационный датасет. Для n-gram модели он не имеет практически смысла, но все равно посмотрим оценки для него."]},{"cell_type":"markdown","metadata":{"id":"8p8H4IUZxf6I"},"source":["Также еще следует сказать о том, что для сравнения моделей обучать мы их должны тоже на одинаковых датасетах, поэтому n-gram модель тоже следут обучать только на трейне "]},{"cell_type":"code","metadata":{"id":"aZ9GGs73cSxk"},"source":["# create integer-to-token mapping\r\n","int2token = {}\r\n","cnt = 0\r\n","\r\n","for w in (PAD,UNK):\r\n","  int2token[cnt] = w\r\n","  cnt+= 1\r\n","\r\n","for w in set(tok for token in train for tok in token):\r\n","  int2token[cnt] = w\r\n","  cnt+= 1\r\n","\r\n","# create token-to-integer mapping\r\n","token2int = {t: i for i, t in int2token.items()}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zeziIRiPcU7k"},"source":["Количественная величина, которая позволяет сравнивать LM: перплекция. Для её вычисления используется следующая формула:\r\n","\r\n","$$\r\n","\\text{Ppr} = \\exp^{\\frac{1}{|D|} \\sum_{t \\in D}\\sum_{w \\in t} - \\log (p(w))},\r\n","$$\r\n","где $D$ – валидационный датасет, $|D|$ – общая длина текстов."]},{"cell_type":"markdown","metadata":{"id":"y85-pmsh9wAG"},"source":["# NGram"]},{"cell_type":"code","metadata":{"id":"1049QaDim5ZN"},"source":["class NGramModel(object):\r\n","  def __init__(self,n=2,k=0.5):\r\n","    self.ngrams = defaultdict(Counter)\r\n","    self.n = n\r\n","    self.vocab_ksmooth = None\r\n","    self.k = k\r\n","\r\n","  def compute_ngrams(self,dataset):\r\n","    self.ngrams = defaultdict(Counter)\r\n","    for sent in tqdm(dataset):\r\n","      ngram = [PAD] * self.n\r\n","      for token in sent:\r\n","        ngram[:-1] = ngram[1:]\r\n","        ngram[-1] = token\r\n","        self.ngrams[tuple(ngram[:-1])].update([ngram[-1]])\r\n","        self.ngrams[(UNK)].update([ngram[-1]])\r\n","    self.vocab_ksmooth = Counter(dict.fromkeys(self.ngrams[(UNK)], self.k))\r\n","\r\n","  def get_probs(self,tokens):\r\n","    if len(tokens)<self.n-1:\r\n","      tokens = [PAD] * (self.n - len(tokens) - 1) + tokens\r\n","    else:\r\n","      tokens = tokens[-self.n + 1:]\r\n","    if len(self.ngrams[tuple(tokens)])>0:\r\n","      possible_predicts = self.ngrams[tuple(tokens)] + self.vocab_ksmooth\r\n","    else: \r\n","      possible_predicts = self.ngrams[(UNK)]\r\n","    sum_freq = sum((possible_predicts.values()))\r\n","    return {tok:possible_predicts[tok]/(sum_freq) for tok in possible_predicts}\r\n","\r\n","  def sample(self, prefix):\r\n","    tokens = tokenize_adv(prefix)\r\n","    possible_predicts = self.get_probs(tokens)\r\n","    if len(possible_predicts) > 0:\r\n","        end = np.random.choice(list(possible_predicts.keys()), p=(list(possible_predicts.values())))\r\n","        return end\r\n","    return EOS\r\n","\r\n","  def generate_text(self, prefix, length=100):\r\n","    text = \"\" + prefix\r\n","    while len(text) < length:\r\n","        token = self.sample(text)\r\n","        text += \" \" + token\r\n","        if token == EOS:\r\n","            break\r\n","    return text\r\n","\r\n","  def perpelexity_ngram(self, data):\r\n","    lengths = 0\r\n","    log_prob = 0\r\n","    for row in tqdm(data):\r\n","        lengths += len(row)\r\n","        ngram = [PAD] * self.n\r\n","        for token in row:\r\n","            ngram[:-1] = ngram[1:]\r\n","            ngram[-1] = token\r\n","            log_prob += np.log(self.get_probs(ngram[:-1]).get(ngram[-1], 0.0001))\r\n","    return np.exp(-log_prob / lengths)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TnX9na3sTu9T"},"source":["treegram = NGramModel(4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":83,"referenced_widgets":["d722d511a966469c8ed41de8dd502880","2fcfecfdb35a4b5db1c251b4d485330b","9db65a244f8442b99019c913e88b2f49","43d7dc52abf0409e880abbed3c185a5a","bb1d3f1538f94a7a88263b32f52a411b","23df277dcbed4791b823b5cc909e4209","986c599f712e461ba4ad5ab69ab499b3","e78429c3ea7945ffb400f830b9b6aad3"]},"id":"W7rPq6KNT9tO","executionInfo":{"status":"ok","timestamp":1612454621500,"user_tz":-180,"elapsed":4291,"user":{"displayName":"Айдар Валиев","photoUrl":"","userId":"09476818626072365934"}},"outputId":"1ae991e3-f9b2-4aa1-c51e-6c50ea70332f"},"source":["treegram.compute_ngrams(train)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d722d511a966469c8ed41de8dd502880","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=31254.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"DONF1_Cf-WNf","executionInfo":{"status":"ok","timestamp":1612454631254,"user_tz":-180,"elapsed":946,"user":{"displayName":"Айдар Валиев","photoUrl":"","userId":"09476818626072365934"}},"outputId":"d4735602-bf87-4d23-e89a-d08d56a29753"},"source":["treegram.generate_text('how ill agrees')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'how ill agrees an scrupulous boy from the the <EOS>'"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":83,"referenced_widgets":["fe4a92a520d24cda9b8fe62676e02bba","98584143c43f4076a3e8d2e07615d6ec","d8af1a07b32c459e97e5f583bb53896a","d0e75d96b8574de88acd1dee13f9e276","bbc91f3fc74241588efee4d06cd71c4a","d1b0c93ff0f3412095a52a5e1a1e6bba","40a24b5413234b5194dcc277a80cb886","bd09d0f05de24db7bbdf1b18b08dcba5"]},"id":"b29ingclyXpC","executionInfo":{"status":"ok","timestamp":1612457867362,"user_tz":-180,"elapsed":944717,"user":{"displayName":"Айдар Валиев","photoUrl":"","userId":"09476818626072365934"}},"outputId":"4fe68aed-a349-470f-d216-bcf5297df9c4"},"source":["print('Perpelexity for 3-gram model on validation set - {}'.format(treegram.perpelexity_ngram(val)))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe4a92a520d24cda9b8fe62676e02bba","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=7814.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Perpelexity for 3-gram model on validation set - 1247.3379081405071\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":83,"referenced_widgets":["24a6e47e5ea4495f99fc403562e18eff","4b8bd8ec1dd24a5aa99652b19b1871ad","f97f099027004a39aeb5ae41c41ea1a8","67852cc093b74531a29603b009dfe687","ac7356e9363647d79856be1f7e416f1f","10c19c29c472420698c5f9fd2d103467","cd464464946c4e2e9e7768bd074821ef","95936afe63044fd19c9f391176b808f5"]},"id":"rm9PwFz6Dez-","executionInfo":{"status":"ok","timestamp":1612459145330,"user_tz":-180,"elapsed":1277936,"user":{"displayName":"Айдар Валиев","photoUrl":"","userId":"09476818626072365934"}},"outputId":"d3f51b04-6bb9-46d8-f2e3-afa90be8f2c6"},"source":["print('Perpelexity for 3-gram model on test set -  {}'.format(treegram.perpelexity_ngram(test)))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"24a6e47e5ea4495f99fc403562e18eff","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=9767.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Perpelexity for 3-gram model on test set -  1294.9876736380197\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":198,"referenced_widgets":["d51c9e0f78854cfeb5bb855fbe422ab3","d46d82a12a6447d088a9bfe6d8f4a8cf","91dba16960644e11a837b4afb44dfdcb","83647abfc49546ecbea86af79b43a695","51acc15257b44283bca6041076714cb4","70594bdab64e4dd78218ed5bc4ef558b","709c5a63f994401ebf4f721a1658d7b9","02bd4bebdca64735942a4ae8deb70b62","05b3d57f4cda4a29a090c60d7f589a05","4c77618388484a1ab737ace3cbd27413","30d77050be274a65ae8b961715cf1907","b3c5c26d026a49c2b20daaeb961ec9cb","77735c881b08402aa3b307c42d3a6b09","bf5c3dd4e7564507bb65408f9309b43e","8bc06ac14e444963a063dd604a56b3da","264e3bc21f354046a6c072dfdb10f9b5","4146195ebaa4417bb4fd7f3057aa1fb6","20fe57d23a2c4b99a40f4ec57fc5a552","5339db67b25e4be5ba82615109f794b8","0cfddcc98eff47f9be514586fa1e1cab","bd3dec50e01c4082ae3bb2a136066577","c211c28f87564969819b274cb93a7a7f","9113199af6b741dfbcd2a6dfdc88e42b","f41176fe41f24e8399bb04574002a902"]},"id":"VePF06cYFT-I","executionInfo":{"status":"ok","timestamp":1612461154563,"user_tz":-180,"elapsed":3287152,"user":{"displayName":"Айдар Валиев","photoUrl":"","userId":"09476818626072365934"}},"outputId":"78265bf9-f8ff-469b-b7c6-a473f8e3034a"},"source":["model = NGramModel(5)\r\n","model.compute_ngrams(train)\r\n","print('Perpelexity for 3-gram model on validation set - {}'.format(model.perpelexity_ngram(val)))\r\n","print('Perpelexity for 3-gram model on test set - {}'.format(model.perpelexity_ngram(test)))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d51c9e0f78854cfeb5bb855fbe422ab3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=31254.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"05b3d57f4cda4a29a090c60d7f589a05","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=7814.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Perpelexity for 3-gram model on validation set - 852.6655317730408\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4146195ebaa4417bb4fd7f3057aa1fb6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=9767.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Perpelexity for 3-gram model on test set - 887.1047522316857\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nV1cd1jme44T"},"source":["#NN"]},{"cell_type":"code","metadata":{"id":"kjAtEaZDWQui"},"source":["# create integer-to-token mapping\r\n","int2token = {}\r\n","cnt = 0\r\n","\r\n","for w in (PAD,UNK):\r\n","  int2token[cnt] = w\r\n","  cnt+= 1\r\n","\r\n","for w in set(tok for token in train for tok in token):\r\n","  int2token[cnt] = w\r\n","  cnt+= 1\r\n","\r\n","# create token-to-integer mapping\r\n","token2int = {t: i for i, t in int2token.items()}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kPDmM4pwZbuR"},"source":["def get_integer_seq(seq):\r\n","  ids=[]\r\n","  for w in seq:\r\n","    if w not in token2int:\r\n","      ids.append(token2int[UNK])\r\n","    else:\r\n","      ids.append(token2int[w])\r\n","  return ids"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L96gdNPVId4X"},"source":["def batch_generator(train_x, train_y, batch_size, shuffle=True, seed=42):\r\n","    if shuffle:  \r\n","      np.random.seed(seed)\r\n","      perm = np.random.permutation(len(train_x))\r\n","    else:\r\n","      perm = np.arange(len(train_x))\r\n","    prv=0\r\n","    for i in range(batch_size, len(train_x), batch_size):\r\n","      x = train_x[perm[prv:i]]\r\n","      y = train_y[perm[prv:i]]\r\n","      prv=i\r\n","      max_len = max(len(i) for i in x)\r\n","      input_embeds_x = np.zeros((len(x), max_len))\r\n","      input_embeds_y = np.zeros((len(y), max_len))\r\n","      for idx, row in enumerate(x):\r\n","        input_embeds_x[idx][:len(row)] += row\r\n","      for idx, row in enumerate(y):\r\n","        input_embeds_y[idx][:len(row)] += row\r\n","      x = torch.LongTensor(input_embeds_x)\r\n","      y = torch.LongTensor(input_embeds_y)\r\n","      yield x, y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ig1we-3-m4oU"},"source":["x_train = []\r\n","y_train = []\r\n","x_val = []\r\n","y_val = []\r\n","for sent in train:\r\n","  try:\r\n","    x_train.append(get_integer_seq(sent[:-1]))\r\n","    y_train.append(get_integer_seq(sent[1:]))\r\n","  except:\r\n","    print(sent,i)\r\n","    break\r\n","\r\n","for sent in val:\r\n","  try:\r\n","    x_val.append(get_integer_seq(sent[:-1]))\r\n","    y_val.append(get_integer_seq(sent[1:]))\r\n","  except:\r\n","    print(sent,i)\r\n","    break  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I8H4s5gMyQb2","executionInfo":{"status":"ok","timestamp":1612866155253,"user_tz":-180,"elapsed":805,"user":{"displayName":"Айдар Валиев","photoUrl":"","userId":"09476818626072365934"}},"outputId":"b0301fdf-c569-4263-84c1-2f07c6949fbc"},"source":["x_train_int = np.array(x_train)\r\n","y_train_int = np.array(y_train)\r\n","x_val_int = np.array(x_val)\r\n","y_val_int = np.array(y_val)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  \"\"\"Entry point for launching an IPython kernel.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  This is separate from the ipykernel package so we can avoid doing imports until\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  after removing the cwd from sys.path.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"AFXmZ0IrTT2F"},"source":["class WordLSTM(nn.Module):\r\n","    \r\n","  def __init__(self,vocab_size=len(token2int), n_hidden=100, n_layers=4, drop_prob=0.3, lr=0.001):\r\n","      super().__init__()\r\n","\r\n","      self.drop_prob = drop_prob\r\n","      self.n_layers = n_layers\r\n","      self.n_hidden = n_hidden\r\n","      self.lr = lr\r\n","      \r\n","      self.emb_layer = nn.Embedding(vocab_size, 300)\r\n","\r\n","      ## define the LSTM\r\n","      self.lstm = nn.LSTM(300, n_hidden, n_layers, \r\n","                          dropout=drop_prob, batch_first=True)\r\n","      \r\n","      ## define a dropout layer\r\n","      self.dropout = nn.Dropout(drop_prob)\r\n","      \r\n","      ## define the fully-connected layer\r\n","      self.fc = nn.Linear(n_hidden, vocab_size)      \r\n","  \r\n","  def forward(self, x, hidden):\r\n","      ''' Forward pass through the network. \r\n","          These inputs are x, and the hidden/cell state `hidden`. '''\r\n","\r\n","      ## pass input through embedding layer\r\n","      embedded = self.emb_layer(x)     \r\n","      \r\n","      ## Get the outputs and the new hidden state from the lstm\r\n","      lstm_output, hidden = self.lstm(embedded, hidden)\r\n","      \r\n","      # ## pass through a dropout layer\r\n","      out = self.dropout(lstm_output)\r\n","      \r\n","      out = out.contiguous().view(-1, self.n_hidden) \r\n","      # out = out.reshape(-1, self.n_hidden) \r\n","      # out = lstm_output.reshape(-1, self.n_hidden) \r\n","\r\n","      ## put \"out\" through the fully-connected layer\r\n","      out = self.fc(out)\r\n","\r\n","      # return the final output and the hidden state\r\n","      return out, hidden\r\n","  \r\n","  \r\n","  def init_hidden(self, batch_size):\r\n","      ''' initializes hidden state '''\r\n","      # Create two new tensors with sizes n_layers x batch_size x n_hidden,\r\n","      # initialized to zero, for hidden state and cell state of LSTM\r\n","      weight = next(self.parameters()).data\r\n","\r\n","      # if GPU is available\r\n","      if (torch.cuda.is_available()):\r\n","        hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\r\n","                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\r\n","      \r\n","      # if GPU is not available\r\n","      else:\r\n","        hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\r\n","                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\r\n","      \r\n","      return hidden\r\n","\r\n","  def sample(self, prefix, h=None, max_length=100):\r\n","    tokens = tokenize_adv(prefix)\r\n","    input_ids = get_integer_seq(tokens)\r\n","    input_ids_tensor = torch.LongTensor(input_ids).unsqueeze(0).to(device)\r\n","    with torch.no_grad():\r\n","      if h==None:\r\n","        h=self.init_hidden(1)\r\n","      while True:\r\n","        h = tuple([each.data for each in h])\r\n","        output, h = self.forward(input_ids_tensor,h)\r\n","        probs = torch.softmax(output[-1,:].cpu(), -1).numpy()\r\n","        next_id = np.random.choice(np.arange(len(token2int)), p=probs)\r\n","        tokens += [int2token[next_id]]\r\n","        if tokens[-1] == EOS or len(tokens) > max_length:\r\n","                break\r\n","        input_ids += [next_id]\r\n","        input_ids_tensor = torch.LongTensor(input_ids).unsqueeze(0).to(device)\r\n","    return \" \".join(t.split(\"_\")[0] for t in tokens)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V42balPSi68p"},"source":["def train_model(net, epochs=10, batch_size=32, lr=0.001, clip=1, print_every=32, shuffle=True, seed=42):\r\n","    \r\n","  # optimizer\r\n","  opt = torch.optim.Adam(net.parameters(), lr=lr)\r\n","  val_pp = 10000\r\n","  # loss\r\n","  criterion = nn.CrossEntropyLoss(ignore_index=token2int[PAD])\r\n","  \r\n","  # push model to GPU\r\n","  # net.cuda()\r\n","  \r\n","  counter = 0\r\n","\r\n","  for e in range(epochs):\r\n","    h = net.init_hidden(batch_size)\r\n","    net.train()        \r\n","    for x, y in batch_generator(x_train_int, y_train_int, batch_size, shuffle=shuffle, seed=seed):\r\n","      counter+= 1\r\n","      inputs, targets = x.to(device), y.to(device)\r\n","      # print(x,y)\r\n","      # print(inputs.shape,targets.shape)\r\n","      h = tuple([each.data for each in h])\r\n","      output, h = net(inputs, h)\r\n","      loss = criterion(output, targets.view(-1))\r\n","      net.zero_grad()\r\n","      loss.backward()\r\n","      nn.utils.clip_grad_norm_(net.parameters(), clip)\r\n","      opt.step()          \r\n","\r\n","      if counter % print_every == 0:\r\n","      \r\n","        print(\"Epoch: {}/{}...\".format(e+1, epochs),\r\n","              \"Step: {}...\".format(counter))\r\n","      # print(\"Epoch: {}/{}...\".format(e+1, epochs),\r\n","      #         \"Step: {}...\".format(counter))\r\n","        # printm()\r\n","            \r\n","    net.eval()\r\n","    valid_loss = 0\r\n","    n_iter = 0\r\n","    with torch.no_grad():\r\n","      for x, y in batch_generator(x_val_int, y_val_int, batch_size):\r\n","        inputs, targets = x.to(device), y.to(device)\r\n","        n_iter += 1\r\n","        prediction, h = net(inputs,h)\r\n","        valid_loss += criterion(prediction, targets.view(-1))\r\n","        valid_perpelexity = torch.exp(valid_loss / n_iter)\r\n","    if valid_perpelexity<=val_pp:\r\n","      val_pp=valid_perpelexity\r\n","      best_model, hidden = copy.deepcopy(net.state_dict()), copy.deepcopy(h)\r\n","    print(f\"Valid Loss: {valid_loss / n_iter}, Valid Peprplexity: {torch.exp(valid_loss / n_iter)}\")\r\n","  return best_model, hidden"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sXHdOhzhMSEA","executionInfo":{"status":"ok","timestamp":1612866167645,"user_tz":-180,"elapsed":11381,"user":{"displayName":"Айдар Валиев","photoUrl":"","userId":"09476818626072365934"}},"outputId":"a3388c6a-7447-41e1-aea7-c50c318cc116"},"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n","net = WordLSTM()\r\n","\r\n","# push the model to GPU (avoid it if you are not using the GPU)\r\n","net.to(device)\r\n","\r\n","print(net)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WordLSTM(\n","  (emb_layer): Embedding(22613, 300)\n","  (lstm): LSTM(300, 100, num_layers=4, batch_first=True, dropout=0.3)\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (fc): Linear(in_features=100, out_features=22613, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ImzKTU3dChJQ","executionInfo":{"status":"ok","timestamp":1612859982015,"user_tz":-180,"elapsed":637048,"user":{"displayName":"Айдар Валиев","photoUrl":"","userId":"09476818626072365934"}},"outputId":"ab55184b-d935-4dab-aeff-ffbdcb3c7036"},"source":["best_model, h = train_model(net, batch_size = 64, epochs=20, print_every=256, shuffle=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch: 1/20... Step: 256...\n","Valid Loss: 6.656827926635742, Valid Peprplexity: 778.0789184570312\n","Epoch: 2/20... Step: 512...\n","Epoch: 2/20... Step: 768...\n","Valid Loss: 6.461060523986816, Valid Peprplexity: 639.7391967773438\n","Epoch: 3/20... Step: 1024...\n","Epoch: 3/20... Step: 1280...\n","Valid Loss: 6.3397393226623535, Valid Peprplexity: 566.6485595703125\n","Epoch: 4/20... Step: 1536...\n","Epoch: 4/20... Step: 1792...\n","Valid Loss: 6.290966033935547, Valid Peprplexity: 539.6744384765625\n","Epoch: 5/20... Step: 2048...\n","Epoch: 5/20... Step: 2304...\n","Valid Loss: 6.247931480407715, Valid Peprplexity: 516.9424438476562\n","Epoch: 6/20... Step: 2560...\n","Epoch: 6/20... Step: 2816...\n","Valid Loss: 6.1983819007873535, Valid Peprplexity: 491.95233154296875\n","Epoch: 7/20... Step: 3072...\n","Epoch: 7/20... Step: 3328...\n","Valid Loss: 6.179967403411865, Valid Peprplexity: 482.9762268066406\n","Epoch: 8/20... Step: 3584...\n","Epoch: 8/20... Step: 3840...\n","Valid Loss: 6.173185348510742, Valid Peprplexity: 479.7117004394531\n","Epoch: 9/20... Step: 4096...\n","Epoch: 9/20... Step: 4352...\n","Valid Loss: 6.170329570770264, Valid Peprplexity: 478.34375\n","Epoch: 10/20... Step: 4608...\n","Epoch: 10/20... Step: 4864...\n","Valid Loss: 6.176663398742676, Valid Peprplexity: 481.3830871582031\n","Epoch: 11/20... Step: 5120...\n","Valid Loss: 6.18323278427124, Valid Peprplexity: 484.5558776855469\n","Epoch: 12/20... Step: 5376...\n","Epoch: 12/20... Step: 5632...\n","Valid Loss: 6.194823741912842, Valid Peprplexity: 490.20501708984375\n","Epoch: 13/20... Step: 5888...\n","Epoch: 13/20... Step: 6144...\n","Valid Loss: 6.211118221282959, Valid Peprplexity: 498.2580871582031\n","Epoch: 14/20... Step: 6400...\n","Epoch: 14/20... Step: 6656...\n","Valid Loss: 6.230584144592285, Valid Peprplexity: 508.05218505859375\n","Epoch: 15/20... Step: 6912...\n","Epoch: 15/20... Step: 7168...\n","Valid Loss: 6.249245643615723, Valid Peprplexity: 517.6221923828125\n","Epoch: 16/20... Step: 7424...\n","Epoch: 16/20... Step: 7680...\n","Valid Loss: 6.258439064025879, Valid Peprplexity: 522.4028930664062\n","Epoch: 17/20... Step: 7936...\n","Epoch: 17/20... Step: 8192...\n","Valid Loss: 6.286914825439453, Valid Peprplexity: 537.4924926757812\n","Epoch: 18/20... Step: 8448...\n","Epoch: 18/20... Step: 8704...\n","Valid Loss: 6.299302577972412, Valid Peprplexity: 544.1922607421875\n","Epoch: 19/20... Step: 8960...\n","Epoch: 19/20... Step: 9216...\n","Valid Loss: 6.327143669128418, Valid Peprplexity: 559.5560302734375\n","Epoch: 20/20... Step: 9472...\n","Epoch: 20/20... Step: 9728...\n","Valid Loss: 6.358843803405762, Valid Peprplexity: 577.5781860351562\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BHHmhn7eu8pU","executionInfo":{"status":"ok","timestamp":1612868188563,"user_tz":-180,"elapsed":887,"user":{"displayName":"Айдар Валиев","photoUrl":"","userId":"09476818626072365934"}},"outputId":"07907677-9012-48dc-9ee1-96ff0b15a48e"},"source":["x_test=[]\r\n","y_test=[]\r\n","for sent in test:\r\n","  try:\r\n","    x_test.append(get_integer_seq(sent[:-1]))\r\n","    y_test.append(get_integer_seq(sent[1:]))\r\n","  except:\r\n","    print(sent)\r\n","    break\r\n","  \r\n","x_test_int = np.array(x_test)\r\n","y_test_int = np.array(y_test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  # This is added back by InteractiveShellApp.init_path()\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  if sys.path[0] == '':\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Iah-dwxvFqZ","executionInfo":{"status":"ok","timestamp":1612860131230,"user_tz":-180,"elapsed":5271,"user":{"displayName":"Айдар Валиев","photoUrl":"","userId":"09476818626072365934"}},"outputId":"e6ee8eb5-2dbd-4914-fdad-2e8ae1b9a6c2"},"source":["net = WordLSTM()\r\n","net.load_state_dict(best_model)\r\n","net.to(device)\r\n","net.eval()\r\n","valid_loss = 0\r\n","n_iter = 0\r\n","criterion = nn.CrossEntropyLoss(ignore_index=token2int[PAD])\r\n","with torch.no_grad():\r\n","  for x, y in batch_generator(x_test_int, y_test_int, 64):\r\n","    inputs, targets = x.to(device), y.to(device)\r\n","    n_iter += 1\r\n","    prediction, h = net(inputs,h)\r\n","    valid_loss += criterion(prediction, targets.view(-1))\r\n","print(f\"Valid Loss: {valid_loss / n_iter}, Peprplexity nn for test set for case without permutation: {torch.exp(valid_loss / n_iter)}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Valid Loss: 6.221892833709717, Peprplexity nn for test set for case without permutation: 503.6556701660156\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d9FMMYKu9IU5","executionInfo":{"status":"ok","timestamp":1612862094054,"user_tz":-180,"elapsed":221406,"user":{"displayName":"Айдар Валиев","photoUrl":"","userId":"09476818626072365934"}},"outputId":"33b72f5a-fd7a-481c-f580-10fde0e3776d"},"source":["net = WordLSTM()\r\n","net.to(device)\r\n","best_model, h = train_model(net, batch_size = 64, epochs=20, print_every=256, shuffle=True, seed=42)\r\n","net.load_state_dict(best_model)\r\n","net.to(device)\r\n","net.eval()\r\n","valid_loss = 0\r\n","n_iter = 0\r\n","criterion = nn.CrossEntropyLoss(ignore_index=token2int[PAD])\r\n","with torch.no_grad():\r\n","  for x, y in batch_generator(x_test_int, y_test_int, 64):\r\n","    inputs, targets = x.to(device), y.to(device)\r\n","    n_iter += 1\r\n","    prediction, h = net(inputs,h)\r\n","    valid_loss += criterion(prediction, targets.view(-1))\r\n","print(f\"Valid Loss: {valid_loss / n_iter}, Peprplexity nn for test set for case with permutation and seed=42: {torch.exp(valid_loss / n_iter)}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch: 1/20... Step: 256...\n","Valid Loss: 6.626049041748047, Valid Peprplexity: 754.495361328125\n","Epoch: 2/20... Step: 512...\n","Epoch: 2/20... Step: 768...\n","Valid Loss: 6.456684112548828, Valid Peprplexity: 636.9454956054688\n","Epoch: 3/20... Step: 1024...\n","Epoch: 3/20... Step: 1280...\n","Valid Loss: 6.35479736328125, Valid Peprplexity: 575.2457275390625\n","Epoch: 4/20... Step: 1536...\n","Epoch: 4/20... Step: 1792...\n","Valid Loss: 6.296908378601074, Valid Peprplexity: 542.8909301757812\n","Epoch: 5/20... Step: 2048...\n","Epoch: 5/20... Step: 2304...\n","Valid Loss: 6.238011837005615, Valid Peprplexity: 511.8398742675781\n","Epoch: 6/20... Step: 2560...\n","Epoch: 6/20... Step: 2816...\n","Valid Loss: 6.1901044845581055, Valid Peprplexity: 487.8970947265625\n","Epoch: 7/20... Step: 3072...\n","Epoch: 7/20... Step: 3328...\n","Valid Loss: 6.16194486618042, Valid Peprplexity: 474.3497009277344\n","Epoch: 8/20... Step: 3584...\n","Epoch: 8/20... Step: 3840...\n","Valid Loss: 6.145797252655029, Valid Peprplexity: 466.7515869140625\n","Epoch: 9/20... Step: 4096...\n","Epoch: 9/20... Step: 4352...\n","Valid Loss: 6.140008926391602, Valid Peprplexity: 464.0577087402344\n","Epoch: 10/20... Step: 4608...\n","Epoch: 10/20... Step: 4864...\n","Valid Loss: 6.141881942749023, Valid Peprplexity: 464.927734375\n","Epoch: 11/20... Step: 5120...\n","Valid Loss: 6.146032810211182, Valid Peprplexity: 466.861572265625\n","Epoch: 12/20... Step: 5376...\n","Epoch: 12/20... Step: 5632...\n","Valid Loss: 6.158846378326416, Valid Peprplexity: 472.8822326660156\n","Epoch: 13/20... Step: 5888...\n","Epoch: 13/20... Step: 6144...\n","Valid Loss: 6.173158168792725, Valid Peprplexity: 479.69866943359375\n","Epoch: 14/20... Step: 6400...\n","Epoch: 14/20... Step: 6656...\n","Valid Loss: 6.186737537384033, Valid Peprplexity: 486.2571105957031\n","Epoch: 15/20... Step: 6912...\n","Epoch: 15/20... Step: 7168...\n","Valid Loss: 6.200841426849365, Valid Peprplexity: 493.163818359375\n","Epoch: 16/20... Step: 7424...\n","Epoch: 16/20... Step: 7680...\n","Valid Loss: 6.215505123138428, Valid Peprplexity: 500.4486999511719\n","Epoch: 17/20... Step: 7936...\n","Epoch: 17/20... Step: 8192...\n","Valid Loss: 6.237131595611572, Valid Peprplexity: 511.3895263671875\n","Epoch: 18/20... Step: 8448...\n","Epoch: 18/20... Step: 8704...\n","Valid Loss: 6.256920337677002, Valid Peprplexity: 521.610107421875\n","Epoch: 19/20... Step: 8960...\n","Epoch: 19/20... Step: 9216...\n","Valid Loss: 6.281776428222656, Valid Peprplexity: 534.73779296875\n","Epoch: 20/20... Step: 9472...\n","Epoch: 20/20... Step: 9728...\n","Valid Loss: 6.30047082901001, Valid Peprplexity: 544.8284301757812\n","Valid Loss: 6.179879188537598, Peprplexity nn for test set for case with permutation and seed=42: 482.9336242675781\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"n-t_8liSjfem","executionInfo":{"status":"ok","timestamp":1612862140020,"user_tz":-180,"elapsed":1274,"user":{"displayName":"Айдар Валиев","photoUrl":"","userId":"09476818626072365934"}},"outputId":"88d20bc4-b130-4207-b4a6-daa1923bcffa"},"source":["net.sample('how ill agrees')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'how ill agrees the lands of what got every thing <EOS>'"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"YZGIRtcWjecO","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1612868224809,"user_tz":-180,"elapsed":4447,"user":{"displayName":"Айдар Валиев","photoUrl":"","userId":"09476818626072365934"}},"outputId":"379d727b-9892-45e4-8a56-c38eec2dfb72"},"source":["# net = WordLSTM()\r\n","# net.to(device)\r\n","# best_model, h = train_model(net, batch_size = 64, epochs=20, print_every=256, shuffle=True, seed=101)\r\n","net.load_state_dict(best_model)\r\n","net.to(device)\r\n","net.eval()\r\n","valid_loss = 0\r\n","n_iter = 0\r\n","criterion = nn.CrossEntropyLoss(ignore_index=token2int[PAD])\r\n","with torch.no_grad():\r\n","  for x, y in batch_generator(x_test_int, y_test_int, 64):\r\n","    inputs, targets = x.to(device), y.to(device)\r\n","    n_iter += 1\r\n","    prediction, h = net(inputs,h)\r\n","    valid_loss += criterion(prediction, targets.view(-1))\r\n","print(f\"Valid Loss: {valid_loss / n_iter}, Peprplexity nn for test set for case with permutation and seed=101: {torch.exp(valid_loss / n_iter)}\")\r\n","net.sample('how ill agrees')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Valid Loss: 6.198301792144775, Peprplexity nn for test set for case with permutation and seed=101: 491.9129638671875\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'how ill agrees up just the king <EOS>'"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"PjQFT_ejE6Qq","executionInfo":{"status":"ok","timestamp":1612868988419,"user_tz":-180,"elapsed":758218,"user":{"displayName":"Айдар Валиев","photoUrl":"","userId":"09476818626072365934"}},"outputId":"6cbb9f3f-e13e-41e9-fccb-acac77fa125b"},"source":["net = WordLSTM()\r\n","net.to(device)\r\n","best_model, h = train_model(net, batch_size = 64, epochs=20, print_every=256, shuffle=True, seed=4)\r\n","net.load_state_dict(best_model)\r\n","net.to(device)\r\n","net.eval()\r\n","valid_loss = 0\r\n","n_iter = 0\r\n","criterion = nn.CrossEntropyLoss(ignore_index=token2int[PAD])\r\n","with torch.no_grad():\r\n","  for x, y in batch_generator(x_test_int, y_test_int, 64):\r\n","    inputs, targets = x.to(device), y.to(device)\r\n","    n_iter += 1\r\n","    prediction, h = net(inputs,h)\r\n","    valid_loss += criterion(prediction, targets.view(-1))\r\n","print(f\"Valid Loss: {valid_loss / n_iter}, Peprplexity nn for test set for case with permutation and seed=4: {torch.exp(valid_loss / n_iter)}\")\r\n","net.sample('how ill agrees')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch: 1/20... Step: 256...\n","Valid Loss: 6.6598124504089355, Valid Peprplexity: 780.404541015625\n","Epoch: 2/20... Step: 512...\n","Epoch: 2/20... Step: 768...\n","Valid Loss: 6.502918720245361, Valid Peprplexity: 667.0858154296875\n","Epoch: 3/20... Step: 1024...\n","Epoch: 3/20... Step: 1280...\n","Valid Loss: 6.359167098999023, Valid Peprplexity: 577.7649536132812\n","Epoch: 4/20... Step: 1536...\n","Epoch: 4/20... Step: 1792...\n","Valid Loss: 6.299463748931885, Valid Peprplexity: 544.280029296875\n","Epoch: 5/20... Step: 2048...\n","Epoch: 5/20... Step: 2304...\n","Valid Loss: 6.2424187660217285, Valid Peprplexity: 514.1005249023438\n","Epoch: 6/20... Step: 2560...\n","Epoch: 6/20... Step: 2816...\n","Valid Loss: 6.194631576538086, Valid Peprplexity: 490.11083984375\n","Epoch: 7/20... Step: 3072...\n","Epoch: 7/20... Step: 3328...\n","Valid Loss: 6.159933567047119, Valid Peprplexity: 473.3966064453125\n","Epoch: 8/20... Step: 3584...\n","Epoch: 8/20... Step: 3840...\n","Valid Loss: 6.144692897796631, Valid Peprplexity: 466.2364196777344\n","Epoch: 9/20... Step: 4096...\n","Epoch: 9/20... Step: 4352...\n","Valid Loss: 6.134138584136963, Valid Peprplexity: 461.3415222167969\n","Epoch: 10/20... Step: 4608...\n","Epoch: 10/20... Step: 4864...\n","Valid Loss: 6.131052494049072, Valid Peprplexity: 459.9199523925781\n","Epoch: 11/20... Step: 5120...\n","Valid Loss: 6.135410785675049, Valid Peprplexity: 461.9288024902344\n","Epoch: 12/20... Step: 5376...\n","Epoch: 12/20... Step: 5632...\n","Valid Loss: 6.137673854827881, Valid Peprplexity: 462.975341796875\n","Epoch: 13/20... Step: 5888...\n","Epoch: 13/20... Step: 6144...\n","Valid Loss: 6.152936935424805, Valid Peprplexity: 470.0959777832031\n","Epoch: 14/20... Step: 6400...\n","Epoch: 14/20... Step: 6656...\n","Valid Loss: 6.166674613952637, Valid Peprplexity: 476.59857177734375\n","Epoch: 15/20... Step: 6912...\n","Epoch: 15/20... Step: 7168...\n","Valid Loss: 6.182574272155762, Valid Peprplexity: 484.23687744140625\n","Epoch: 16/20... Step: 7424...\n","Epoch: 16/20... Step: 7680...\n","Valid Loss: 6.195996284484863, Valid Peprplexity: 490.7801513671875\n","Epoch: 17/20... Step: 7936...\n","Epoch: 17/20... Step: 8192...\n","Valid Loss: 6.216447830200195, Valid Peprplexity: 500.9206848144531\n","Epoch: 18/20... Step: 8448...\n","Epoch: 18/20... Step: 8704...\n","Valid Loss: 6.2325286865234375, Valid Peprplexity: 509.0410461425781\n","Epoch: 19/20... Step: 8960...\n","Epoch: 19/20... Step: 9216...\n","Valid Loss: 6.245913028717041, Valid Peprplexity: 515.9000854492188\n","Epoch: 20/20... Step: 9472...\n","Epoch: 20/20... Step: 9728...\n","Valid Loss: 6.273528099060059, Valid Peprplexity: 530.3451538085938\n","Valid Loss: 6.170627117156982, Peprplexity nn for test set for case with permutation and seed=4: 478.4860534667969\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'how ill agrees we hast forgot the weather whom the hire softly out of her as drive my pleasure in dull to so stray to steal <EOS>'"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"_dHliHJai1kI","executionInfo":{"status":"ok","timestamp":1612870787222,"user_tz":-180,"elapsed":758174,"user":{"displayName":"Айдар Валиев","photoUrl":"","userId":"09476818626072365934"}},"outputId":"541f3c2a-6299-467f-e807-c2113b73f17f"},"source":["net = WordLSTM()\r\n","net.to(device)\r\n","best_model, h = train_model(net, batch_size = 64, epochs=20, print_every=256, shuffle=True, seed=63)\r\n","net.load_state_dict(best_model)\r\n","net.to(device)\r\n","net.eval()\r\n","valid_loss = 0\r\n","n_iter = 0\r\n","criterion = nn.CrossEntropyLoss(ignore_index=token2int[PAD])\r\n","with torch.no_grad():\r\n","  for x, y in batch_generator(x_test_int, y_test_int, 64):\r\n","    inputs, targets = x.to(device), y.to(device)\r\n","    n_iter += 1\r\n","    prediction, h = net(inputs,h)\r\n","    valid_loss += criterion(prediction, targets.view(-1))\r\n","print(f\"Valid Loss: {valid_loss / n_iter}, Peprplexity nn for test set for case with permutation and seed=63: {torch.exp(valid_loss / n_iter)}\")\r\n","net.sample('how ill agrees')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch: 1/20... Step: 256...\n","Valid Loss: 6.682488441467285, Valid Peprplexity: 798.30322265625\n","Epoch: 2/20... Step: 512...\n","Epoch: 2/20... Step: 768...\n","Valid Loss: 6.476461887359619, Valid Peprplexity: 649.6682739257812\n","Epoch: 3/20... Step: 1024...\n","Epoch: 3/20... Step: 1280...\n","Valid Loss: 6.362300872802734, Valid Peprplexity: 579.5783081054688\n","Epoch: 4/20... Step: 1536...\n","Epoch: 4/20... Step: 1792...\n","Valid Loss: 6.306774139404297, Valid Peprplexity: 548.2734375\n","Epoch: 5/20... Step: 2048...\n","Epoch: 5/20... Step: 2304...\n","Valid Loss: 6.2605462074279785, Valid Peprplexity: 523.5048217773438\n","Epoch: 6/20... Step: 2560...\n","Epoch: 6/20... Step: 2816...\n","Valid Loss: 6.2092742919921875, Valid Peprplexity: 497.34014892578125\n","Epoch: 7/20... Step: 3072...\n","Epoch: 7/20... Step: 3328...\n","Valid Loss: 6.177935600280762, Valid Peprplexity: 481.9958801269531\n","Epoch: 8/20... Step: 3584...\n","Epoch: 8/20... Step: 3840...\n","Valid Loss: 6.16451358795166, Valid Peprplexity: 475.5697326660156\n","Epoch: 9/20... Step: 4096...\n","Epoch: 9/20... Step: 4352...\n","Valid Loss: 6.15546989440918, Valid Peprplexity: 471.2882385253906\n","Epoch: 10/20... Step: 4608...\n","Epoch: 10/20... Step: 4864...\n","Valid Loss: 6.159589767456055, Valid Peprplexity: 473.23388671875\n","Epoch: 11/20... Step: 5120...\n","Valid Loss: 6.163481712341309, Valid Peprplexity: 475.0792541503906\n","Epoch: 12/20... Step: 5376...\n","Epoch: 12/20... Step: 5632...\n","Valid Loss: 6.174457550048828, Valid Peprplexity: 480.3223876953125\n","Epoch: 13/20... Step: 5888...\n","Epoch: 13/20... Step: 6144...\n","Valid Loss: 6.181601047515869, Valid Peprplexity: 483.765869140625\n","Epoch: 14/20... Step: 6400...\n","Epoch: 14/20... Step: 6656...\n","Valid Loss: 6.208013534545898, Valid Peprplexity: 496.7135314941406\n","Epoch: 15/20... Step: 6912...\n","Epoch: 15/20... Step: 7168...\n","Valid Loss: 6.217546463012695, Valid Peprplexity: 501.4713439941406\n","Epoch: 16/20... Step: 7424...\n","Epoch: 16/20... Step: 7680...\n","Valid Loss: 6.230520725250244, Valid Peprplexity: 508.0199279785156\n","Epoch: 17/20... Step: 7936...\n","Epoch: 17/20... Step: 8192...\n","Valid Loss: 6.249335765838623, Valid Peprplexity: 517.6688842773438\n","Epoch: 18/20... Step: 8448...\n","Epoch: 18/20... Step: 8704...\n","Valid Loss: 6.263710975646973, Valid Peprplexity: 525.1641845703125\n","Epoch: 19/20... Step: 8960...\n","Epoch: 19/20... Step: 9216...\n","Valid Loss: 6.2889556884765625, Valid Peprplexity: 538.590576171875\n","Epoch: 20/20... Step: 9472...\n","Epoch: 20/20... Step: 9728...\n","Valid Loss: 6.307270526885986, Valid Peprplexity: 548.545654296875\n","Valid Loss: 6.193968772888184, Peprplexity nn for test set for case with permutation and seed=63: 489.7861022949219\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'how ill agrees sparkling like nero which hurry from upright self late unto some addition and at my merry honour live a sucking barbermonger standing hath companyof unmake against him with that emmence and beggar for a war that this hours flies <EOS>'"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"VEkwmPsiiZ-z"},"source":["Как видим, получается разный результат в зависимости от параметра seed. Также заметим, что в случае без перемешивания порядка предложений модель показала худший результат. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PQYLYZ44a7ed","executionInfo":{"status":"ok","timestamp":1612378702465,"user_tz":-180,"elapsed":1423052,"user":{"displayName":"Айдар Валиев","photoUrl":"","userId":"09476818626072365934"}},"outputId":"05d5bcbd-ca75-41fe-f5aa-de0439372e32"},"source":["# memory footprint support libraries/code\r\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\r\n","!pip install gputil\r\n","!pip install psutil\r\n","!pip install humanize\r\n","import psutil\r\n","import humanize\r\n","import os\r\n","import GPUtil as GPU\r\n","GPUs = GPU.getGPUs()\r\n","# XXX: only one GPU on Colab and isnt guaranteed\r\n","gpu = GPUs[0]\r\n","def printm():\r\n"," process = psutil.Process(os.getpid())\r\n"," print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\r\n"," GPUs = GPU.getGPUs()\r\n"," # XXX: only one GPU on Colab and isnt guaranteed\r\n"," gpu = GPUs[0]\r\n"," print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\r\n","printm()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","Gen RAM Free: 12.4 GB  | Proc size: 667.0 MB\n","GPU RAM Free: 15069MB | Used: 10MB | Util   0% | Total 15079MB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z_1UlwIclRLL"},"source":["# seqs_train = [create_seq(i,8) for i in train]\r\n","\r\n","# # merge list-of-lists into a single list\r\n","# seqs_train = sum(seqs_train, [])\r\n","\r\n","# # count of sequences\r\n","# len(seqs_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J7s6N0ID59H1"},"source":["# seqs_val = [create_seq(i,8) for i in val]\r\n","\r\n","# # merge list-of-lists into a single list\r\n","# seqs_val = sum(seqs_val, [])\r\n","\r\n","# # count of sequences\r\n","# len(seqs_val)"],"execution_count":null,"outputs":[]}]}